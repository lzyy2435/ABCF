{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5643e5-e5ed-4d4d-a95a-76494bd8457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res_(values: list):\n",
    "    value_cnt = {}  # 将结果用一个字典存储\n",
    "    # 统计结果\n",
    "    for value in values:\n",
    "        # get(value, num)函数的作用是获取字典中value对应的键值, num=0指示初始值大小。\n",
    "        value_cnt[value] = value_cnt.get(value, 0) + 1\n",
    "\n",
    "    # 打印输出结果\n",
    "    print(value_cnt)\n",
    "    print([key for key in value_cnt.keys()])\n",
    "    print([value for value in value_cnt.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3726a-a9ac-4920-b4b0-4496c9a016cd",
   "metadata": {},
   "source": [
    "## 对全部数据集train1和train1补充进行过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3465af87-6782-478a-a27a-e8f4597e1cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取数据完成\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re, collections, math, datetime\n",
    "import json\n",
    "import collections\n",
    "\n",
    "import sklearn\n",
    "import sklearn.svm as svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def getDomainFeature(domain: str):\n",
    "    feature = [domain.count('.'), len(domain), sum(c.isdigit() for c in domain), domain.count('-')]\n",
    "\n",
    "    count_c = 0\n",
    "    special_characters = (':', ';', '#', '!', '%', '~', '+', '_', '?', '=', '&', '[', ']')\n",
    "    for c in domain:\n",
    "        if c in special_characters:\n",
    "            count_c = count_c + 1\n",
    "    feature.append(count_c)\n",
    "\n",
    "    s = len(domain)\n",
    "    dd = collections.defaultdict(int)\n",
    "    for c in domain:\n",
    "        dd[c] += 1\n",
    "\n",
    "    # 字符随机性\n",
    "    # H(d) = － ∑lg( P( Xi ) ) * P( Xi )\n",
    "    feature.append(sum(map(lambda value: -(value / s) * math.log2(value / s), dd.values())))\n",
    "\n",
    "    # 元音字母比例\n",
    "    feature.append(sum(map(lambda x: dd[x], ('a', 'e', 'i', 'o', 'u'))) / s)\n",
    "\n",
    "    # 唯一字符数\n",
    "    feature.append(len(dd))\n",
    "\n",
    "    return feature\n",
    "\n",
    "\n",
    "def getIPFeature(ip: str):\n",
    "    if ':' in ip:\n",
    "        x = ip.split(':')\n",
    "        feature = x[0].split('.') + [x[1]]\n",
    "    else:\n",
    "        feature = ip.split('.') + [80]\n",
    "    feature = list(map(lambda x: int(x), feature))\n",
    "    return feature\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ip_pool = []\n",
    "    ip_label = []\n",
    "\n",
    "    domain_pool = []\n",
    "    domain_label = []\n",
    "    url_pool = []\n",
    "\n",
    "    n = 0\n",
    "    count = 0\n",
    "    path1 = r\"suspect_pool_new.txt\"\n",
    "    for _ in csv.reader(open(path1)):\n",
    "        try:\n",
    "            if re.match(r\"^\\d+\\.\\d+\\.\\d+\\.\\d+(:\\d+)?$\", _[0]):\n",
    "                ip_pool.append(getIPFeature(_[0]))\n",
    "                ip_label.append(int(_[1]))\n",
    "            else:\n",
    "                if n > 50000:\n",
    "                    break\n",
    "                domain_label.append(int(_[1]))\n",
    "                domain_pool.append(getDomainFeature(_[0]))\n",
    "                url_pool.append(_[0])\n",
    "                if _[1] != '0':\n",
    "                    count+=1\n",
    "        except:\n",
    "            print(_)\n",
    "        n += 1\n",
    "        if n % 100000 == 0:\n",
    "            # break\n",
    "            print(f\"已读取分析{n}个数据\")\n",
    "            \n",
    "    path2 = \"data1add.csv\"\n",
    "    for _ in csv.reader(open(path2)):\n",
    "        try:\n",
    "            if re.match(r\"^\\d+\\.\\d+\\.\\d+\\.\\d+(:\\d+)?$\", _[0]):\n",
    "                ip_pool.append(getIPFeature(_[0]))\n",
    "                ip_label.append(int(_[1]))\n",
    "            else:\n",
    "                domain_label.append(int(_[1]))\n",
    "                domain_pool.append(getDomainFeature(_[0]))\n",
    "                url_pool.append(_[0])\n",
    "        except:\n",
    "            print(_)\n",
    "            \n",
    "        n += 1\n",
    "        if n % 100000 == 0:\n",
    "            # break\n",
    "            print(f\"已读取分析{n}个数据\")\n",
    "            \n",
    "    print(\"读取数据完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e5ba08-0866-451b-93cb-17a82a3f456a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: 3, 8: 8, 4: 406}\n",
      "[3, 8, 4]\n",
      "[3, 8, 406]\n",
      "{2: 11489, 6: 2599, 9: 557, 10: 35, 11: 56, 1: 14, 5: 2, 0: 35249, 3: 170, 7: 11, 8: 875, 12: 7, 4: 4252}\n",
      "[2, 6, 9, 10, 11, 1, 5, 0, 3, 7, 8, 12, 4]\n",
      "[11489, 2599, 557, 35, 56, 14, 2, 35249, 170, 11, 875, 7, 4252]\n"
     ]
    }
   ],
   "source": [
    "# get_res_(ip_pool)\n",
    "get_res_(ip_label)\n",
    "# get_res_(domain_pool)\n",
    "get_res_(domain_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16193f22-fc3d-46d9-87e0-abb44155dffd",
   "metadata": {},
   "source": [
    "### 开始XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97d164b-fd1e-4c54-b64b-a2c65e22aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_model(x_train,y_train):\n",
    "    \"\"\"用XGBoost进行建模，返回训练好的模型\"\"\"\n",
    "    xgboost_clf = XGBClassifier(min_child_weight=6,max_depth=15,\n",
    "                                objective='multi:softmax',num_class=13)\n",
    "    print(\"-\" * 60)\n",
    "    print(\"xgboost模型：\", xgboost_clf)\n",
    "    xgboost_clf.fit(x_train, y_train)\n",
    "    # # 打印重要性指数\n",
    "    # importance_features_top('xgboost', xgboost_clf, x_train)\n",
    "    # 保存模型\n",
    "    xgboost_clf.save_model('xgboost_50_3.json')\n",
    "    # joblib.dump(xgboost_clf, r'XGBoost_model_v1.0')\n",
    "    return xgboost_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04d0f2d-feb1-42cb-9728-f32dd1578e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:06:30] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"scale_pos_weight\", \"silent\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# 切分训练集和测试集\n",
    "train_x, test_x, train_y, test_y = train_test_split(domain_pool,domain_label,test_size=0.2,random_state=7)\n",
    "\n",
    "# xgboost模型初始化设置\n",
    "xgboost_clf = XGBClassifier(min_child_weight=6,max_depth=10,scale_pos_weight=5,n_estimators=200,\n",
    "                                objective='multi:softmax',num_class=13,silent=False)\n",
    "\n",
    "# 建模\n",
    "# xgboost_clf = xgboost_model(train_x, train_y)\n",
    "xgboost_clf.fit(train_x, train_y)\n",
    "# # 打印重要性指数\n",
    "# importance_features_top('xgboost', xgboost_clf, x_train)\n",
    "# 保存模型\n",
    "xgboost_clf.save_model('xgboost_50-part-new.json')\n",
    "# 预测\n",
    "pre_y_test = xgboost_clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b5ae5f-88d6-4c71-9009-3ea44139e473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 0 0 2 0 2 2 0 0 2 2 0 2 0 0 8 0 0 0 0 0 2 0 2 0 2 4 0 0 0 2 2 0 0\n",
      " 2 0 4 0 0 2 0 0 0 0 0 0 2 2 2 2 0 0 2 4 2 2 2 0 0 2 2 0 0 0 0 2 0 0 0 2 0\n",
      " 2 2 0 0 0 4 0 0 0 8 2 2 2 0 0 2 2 0 2 2 6 0 0 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "# domain_label_a = np.asarray(domain_label_a,dtype=np.int32)\n",
    "\n",
    "# domain_pool_a = preprocessing.scale(domain_pool_a)\n",
    "\n",
    "pred_y = pre_y_test # np.around(ypred)\n",
    "pred_y = pred_y.astype(int)# domain_svm_model.predict(domain_pool_a)\n",
    "# pred_y_p = domain_svm_model.predict_proba(domain_pool_a)\n",
    "print(pred_y[500:600])\n",
    "# get_res_(pred_y)\n",
    "label_y = test_y\n",
    "# print(label_y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51040318-3690-4ebe-9d2d-83f396b67e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集\u001b[0;34m准确率\u001b[0m为\u001b[0;31m74.88%\n",
      "\u001b[0m测试集\u001b[0;34mf1_micro值\u001b[0m为\u001b[0;31m74.88%\n",
      "\u001b[0m测试集\u001b[0;34mrecall_micro值\u001b[0m为\u001b[0;31m74.88%\n",
      "\u001b[0m测试集\u001b[0;34mprecision_micro值\u001b[0m为\u001b[0;31m74.88%\u001b[0m\n",
      "\u001b[0m测试集\u001b[0;34mf1_macro值\u001b[0m为\u001b[0;31m24.68%\n",
      "\u001b[0m测试集\u001b[0;34mrecall_macro值\u001b[0m为\u001b[0;31m22.59%\n",
      "\u001b[0m测试集\u001b[0;34mprecision_macro值\u001b[0m为\u001b[0;31m38.40%\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 评估\n",
    "now = datetime.datetime.now()\n",
    "timestamp = datetime.datetime.timestamp(now)\n",
    "\n",
    "TF = {\"timestamp\":timestamp,\n",
    "      \"randomSeed\":42,\n",
    "      # \"训练集规模\":int(domain_size * 0.8),\n",
    "      # \"测试集规模\":domain_size - int(domain_size * 0.8),\n",
    "      # \"标准化均值\":tuple(domain_pool.mean(axis=0)),\n",
    "      # \"标准化方差\":tuple(domain_pool.std(axis=0)),\n",
    "      \"准确率\": accuracy_score(label_y, pred_y),\n",
    "      \"f1_micro\": f1_score(label_y, pred_y,average=\"micro\"),\n",
    "      \"precision_micro\": precision_score(label_y, pred_y,average=\"micro\"),\n",
    "      \"recall_micro\": recall_score(label_y, pred_y,average=\"micro\"),\n",
    "      # \"auc_micro\": roc_auc_score(label_y, pred_y,average=\"micro\"),\n",
    "      \n",
    "      \"f1_macro\": f1_score(label_y, pred_y,average=\"macro\"),\n",
    "      \"recall_macro\": recall_score(label_y, pred_y,average=\"macro\"),\n",
    "      # \"auc_macro\": roc_auc_score(label_y, pred_y,average=\"macro\"),\n",
    "      \"precision_macro\": precision_score(label_y, pred_y,average=\"macro\"),\n",
    "\n",
    "      \"模型名称\": \"xgboost2\"\n",
    "      }\n",
    "\n",
    "with open(\"log_\"+TF[\"模型名称\"]+\".json\",\"w\") as f:\n",
    "    b = json.dumps(TF)\n",
    "    f.write(b)\n",
    "\n",
    "print(f\"测试集\\033[0;34m准确率\\033[0m为\\033[0;31m{TF['准确率'] * 100:.2f}%\")\n",
    "print(f\"\\033[0m测试集\\033[0;34mf1_micro值\\033[0m为\\033[0;31m{TF['f1_micro'] * 100:.2f}%\")\n",
    "print(f\"\\033[0m测试集\\033[0;34mrecall_micro值\\033[0m为\\033[0;31m{TF['recall_micro'] * 100:.2f}%\")\n",
    "# print(f\"\\033[0m测试集\\033[0;34mroc值\\033[0m为\\033[0;31m{TF['auc_micro'] * 100:.2f}%\")\n",
    "print(f\"\\033[0m测试集\\033[0;34mprecision_micro值\\033[0m为\\033[0;31m{TF['precision_micro'] * 100:.2f}%\\033[0m\")\n",
    "print(f\"\\033[0m测试集\\033[0;34mf1_macro值\\033[0m为\\033[0;31m{TF['f1_macro'] * 100:.2f}%\")\n",
    "print(f\"\\033[0m测试集\\033[0;34mrecall_macro值\\033[0m为\\033[0;31m{TF['recall_macro'] * 100:.2f}%\")\n",
    "# print(f\"\\033[0m测试集\\033[0;34mroc_macro值\\033[0m为\\033[0;31m{TF['auc_macro'] * 100:.2f}%\")\n",
    "print(f\"\\033[0m测试集\\033[0;34mprecision_macro值\\033[0m为\\033[0;31m{TF['precision_macro'] * 100:.2f}%\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d338d39-f9a0-4e70-aa92-bd4ee4695995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e7896-9add-4b02-a208-909ccddc7429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fee1dc5-bc97-4fc5-bb33-827121065e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已读取分析100000个数据\n",
      "读取数据完成\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re, collections, math, datetime\n",
    "import json\n",
    "import collections\n",
    "\n",
    "import sklearn\n",
    "import sklearn.svm as svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def getDomainFeature(domain: str):\n",
    "    feature = [domain.count('.'), len(domain), sum(c.isdigit() for c in domain), domain.count('-')]\n",
    "\n",
    "    count_c = 0\n",
    "    special_characters = (':', ';', '#', '!', '%', '~', '+', '_', '?', '=', '&', '[', ']')\n",
    "    for c in domain:\n",
    "        if c in special_characters:\n",
    "            count_c = count_c + 1\n",
    "    feature.append(count_c)\n",
    "\n",
    "    s = len(domain)\n",
    "    dd = collections.defaultdict(int)\n",
    "    for c in domain:\n",
    "        dd[c] += 1\n",
    "\n",
    "    # 字符随机性\n",
    "    # H(d) = － ∑lg( P( Xi ) ) * P( Xi )\n",
    "    feature.append(sum(map(lambda value: -(value / s) * math.log2(value / s), dd.values())))\n",
    "\n",
    "    # 元音字母比例\n",
    "    feature.append(sum(map(lambda x: dd[x], ('a', 'e', 'i', 'o', 'u'))) / s)\n",
    "\n",
    "    # 唯一字符数\n",
    "    feature.append(len(dd))\n",
    "\n",
    "    return feature\n",
    "\n",
    "\n",
    "def getIPFeature(ip: str):\n",
    "    if ':' in ip:\n",
    "        x = ip.split(':')\n",
    "        feature = x[0].split('.') + [x[1]]\n",
    "    else:\n",
    "        feature = ip.split('.') + [80]\n",
    "    feature = list(map(lambda x: int(x), feature))\n",
    "    return feature\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ip_pool = []\n",
    "    ip_label = []\n",
    "\n",
    "    domain_pool = []\n",
    "    domain_label = []\n",
    "    url_pool = []\n",
    "\n",
    "    n = 0\n",
    "    count = 0\n",
    "    path1 = r\"url_suspect_test.txt\"\n",
    "    for _ in csv.reader(open(path1)):\n",
    "        # print(_[0])\n",
    "        try:\n",
    "            if re.match(r\"^\\d+\\.\\d+\\.\\d+\\.\\d+(:\\d+)?$\", _[0]):\n",
    "                ip_pool.append(getIPFeature(_[0]))\n",
    "                # ip_label.append(int(_[1]))\n",
    "            else:\n",
    "                # domain_label.append(int(_[1]))\n",
    "                domain_pool.append(getDomainFeature(_[0]))\n",
    "                url_pool.append(_[0])\n",
    "                # if _[1] != '0':\n",
    "                    # count+=1\n",
    "        except:\n",
    "            print(_)\n",
    "        n += 1\n",
    "        if n % 100000 == 0:\n",
    "            # break\n",
    "            print(f\"已读取分析{n}个数据\")\n",
    "            \n",
    "    # path2 = \"data1add.csv\"\n",
    "    # for _ in csv.reader(open(path2)):\n",
    "    #     try:\n",
    "    #         if re.match(r\"^\\d+\\.\\d+\\.\\d+\\.\\d+(:\\d+)?$\", _[0]):\n",
    "    #             ip_pool.append(getIPFeature(_[0]))\n",
    "    #             ip_label.append(int(_[1]))\n",
    "    #         else:\n",
    "    #             domain_label.append(int(_[1]))\n",
    "    #             domain_pool.append(getDomainFeature(_[0]))\n",
    "    #             url_pool.append(_[0])\n",
    "    #     except:\n",
    "    #         print(_)\n",
    "            \n",
    "        # n += 1\n",
    "        # if n % 100000 == 0:\n",
    "        #     # break\n",
    "        #     print(f\"已读取分析{n}个数据\")\n",
    "            \n",
    "    print(\"读取数据完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8273dd4a-55f3-459e-a9f0-e90ab6fa5d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e242a823-9c44-4771-bbc6-4bde53c4776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_y_test = xgboost_clf.predict(domain_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c4d686a-ed6e-4206-b338-d431c443e978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161381\n",
      "161381\n",
      "161381\n"
     ]
    }
   ],
   "source": [
    "print(len(pre_y_test))\n",
    "print(len(domain_pool))\n",
    "print(len(url_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8697214-fb29-43bd-a3f5-e02f8f656254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 138714, 2: 18945, 9: 382, 4: 2095, 6: 856, 8: 370, 3: 9, 11: 10}\n",
      "[0, 2, 9, 4, 6, 8, 3, 11]\n",
      "[138714, 18945, 382, 2095, 856, 370, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "get_res_(pre_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b36457f9-037d-4489-9ff1-ceabce2c611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test-xgb.csv', 'w', newline='\\n') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',')#,\n",
    "                            # quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(len(url_pool)): \n",
    "        spamwriter.writerow([url_pool[i],pre_y_test[i]])\n",
    "    # spamwriter.writerow(['Spam', 'Lovely Spam', 'Wonderful Spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd942531-cb42-4345-bcb8-be6019296946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.8",
   "language": "python",
   "name": "torch1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
